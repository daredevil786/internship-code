
Introduction to Pandas
pandas is a Python package providing fast, flexible, and expressive data structures designed to work with relational or labeled data both. It is a fundamental high-level building block for executing practical, real world data analysis in Python.

pandas is well suited for:

Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet
Ordered and unordered (not necessarily fixed-frequency) time series data.
Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels
Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure
Key features:

Easy handling of missing data
Size mutability: columns can be inserted and deleted from DataFrame and higher dimensional objects
Automatic and explicit data alignment: objects can be explicitly aligned to a set of labels, or the data can be aligned automatically
Powerful, flexible group by functionality to perform split-apply-combine operations on data sets
Intelligent label-based slicing, fancy indexing, and subsetting of large data sets
Intuitive merging and joining data sets
Flexible reshaping and pivoting of data sets
Hierarchical labeling of axes
Robust IO tools for loading data from flat files, Excel files, databases, and HDF5
Time series functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging, etc.
Installing and Using Pandas
Installation of Pandas on your system requires NumPy to be installed, and if building the library from source, requires the appropriate tools to compile the C and Cython sources on which Pandas is built. Details on this installation can be found in the Pandas documentation.

Once Pandas is installed, you can import it and check the version:

In [ ]:
import pandas
pandas.__version__
Out[ ]:
'0.24.2'
Introducing Pandas Objects
At the very basic level, Pandas objects can be thought as enhanced versions of NumPy structured arrays in which the rows and columns are identified with labels rather than simple integer indices. As we will see during the course of this chapter, Pandas provide a host of useful tools, methods, and functionality on top of the basic data structures, but nearly everything that follows will require an understanding of what these structures are. Thus, before we go any further, let's introduce these three fundamental Pandas data structures: the Series, DataFrame, and Index.

We will start our code sessions with the standard NumPy and Pandas imports:

In [ ]:
import numpy as np
import pandas as pd
Series
A Series is a single vector of data (like a NumPy array) with an index that labels each element in the vector.

In [ ]:
counts = pd.Series([632, 1638, 569, 115])
counts
Out[ ]:
0     632
1    1638
2     569
3     115
dtype: int64
If an index is not specified, a default sequence of integers is assigned as the index. A NumPy array comprises the values of the Series, while the index is a pandas Index object.

In [ ]:
counts.values
In [ ]:
counts.index
We can assign meaningful labels to the index, if they are available:

In [ ]:
bacteria = pd.Series([632, 1638, 569, 115], 
    index=['Firmicutes', 'Proteobacteria', 'Actinobacteria', 'Bacteroidetes'])

bacteria
These labels can be used to refer to the values in the Series.

In [ ]:
bacteria['Actinobacteria']
Notice that the indexing operation preserve the association between the values and the corresponding indices.

We can still use positional indexing if we wish.

In [ ]:
bacteria[0]
We can give both the array of values and the index meaningful labels themselves:

In [ ]:
bacteria.name = 'counts'
bacteria.index.name = 'phylum'
bacteria
NumPy's math functions and other operations can be applied to Series without losing the data structure.

In [ ]:
np.log(bacteria)
We can also filter according to the values in the Series:

In [ ]:
bacteria[bacteria>1000]
A Series can be thought of as an ordered key-value store. In fact, we can create one from a dict:

In [ ]:
bacteria_dict = {'Firmicutes': 632, 'Proteobacteria': 1500, 'Actinobacteria': 569, 'Bacteroidetes': 115}
print(bacteria_dict)
pd.Series(bacteria_dict)
Series as generalized NumPy array
From what we've seen so far, it may look like the Series object is basically interchangeable with a one-dimensional NumPy array. The essential difference is the presence of the index: while the Numpy Array has an implicitly defined integer index used to access the values, the Pandas Series has an explicitly defined index associated with the values.

This explicit index definition gives the Series object additional capabilities.

Series as specialized dictionary
In this way, you can think of a Pandas Series a bit like a specialization of Python dictionary. A dictionary is a structure that maps arbitrary keys to set of arbitrary values, and Series is a structure which maps typed keys to a set of typed values. This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than Python list for certain operations, the type information of a Pandas Series makes it much more efficient than Python dictionaries for certain operations.

The Series-as-dictionary analogy can be made even more clear by constructing a Series object directly from Python dictionary:

DataFrame: bi-dimensional Series with two (or more) indices
A DataFrame represents a tabular, spreadsheet-like data structure containing an ordered collection of columns, each of which can be a different value type (numeric, string, boolean, etc.).

The DataFrame has both row and column index; it can be thought of as a dict of Series (all sharing the same index).

DataFrame's can be created in different ways. One of them is from dict's.

In [ ]:
data = {"Province": ["FL", "FL", "NH", "NH", "ZH"],
        "Year": [2013, 2014, 2013, 2014, 2014],
        "Literacy": [0.2, 0.1, 0.5, 0.3, 0.5]}
print(data)
data = pd.DataFrame(data)
data
{'Province': ['FL', 'FL', 'NH', 'NH', 'ZH'], 'Year': [2013, 2014, 2013, 2014, 2014], 'Literacy': [0.2, 0.1, 0.5, 0.3, 0.5]}
Out[ ]:
Province	Year	Literacy
0	FL	2013	0.2
1	FL	2014	0.1
2	NH	2013	0.5
3	NH	2014	0.3
4	ZH	2014	0.5
To change the order of the columns:

In [ ]:
df = pd.DataFrame(data, columns=["Year", "Province" ,"Literacy"])
df
Out[ ]:
Year	Province	Literacy
0	2013	FL	0.2
1	2014	FL	0.1
2	2013	NH	0.5
3	2014	NH	0.3
4	2014	ZH	0.5
An index can be passed (as with Series), and passing column names not existing, will result in missing data.

Assigning values to new columns is easy

In [ ]:
df['nonsense'] = df.Year / df.Literacy
df
Out[ ]:
Year	Province	Literacy	nonsense
0	2013	FL	0.2	10065.000000
1	2014	FL	0.1	20140.000000
2	2013	NH	0.5	4026.000000
3	2014	NH	0.3	6713.333333
4	2014	ZH	0.5	4028.000000
In [ ]:
df['Serie_aligned'] = pd.Series(range(5), index=[0,1,2, 3, 4])
df
Out[ ]:
Year	Province	Literacy	nonsense	Serie_aligned
0	2013	FL	0.2	10065.000000	0
1	2014	FL	0.1	20140.000000	1
2	2013	NH	0.5	4026.000000	2
3	2014	NH	0.3	6713.333333	3
4	2014	ZH	0.5	4028.000000	4
Passing a dicts where the values are dicts is also possible

In [ ]:
df.to_dict()
Out[ ]:
{'Year': {0: 2013, 1: 2014, 2: 2013, 3: 2014, 4: 2014},
 'Province': {0: 'FL', 1: 'FL', 2: 'NH', 3: 'NH', 4: 'ZH'},
 'Literacy': {0: 0.2, 1: 0.1, 2: 0.5, 3: 0.3, 4: 0.5},
 'nonsense': {0: 10065.0,
  1: 20140.0,
  2: 4026.0,
  3: 6713.333333333334,
  4: 4028.0},
 'Serie_aligned': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}}
In [ ]:
pd.DataFrame(df.to_dict())
Out[ ]:
Year	Province	Literacy	nonsense	Serie_aligned
0	2013	FL	0.2	10065.000000	0
1	2014	FL	0.1	20140.000000	1
2	2013	NH	0.5	4026.000000	2
3	2014	NH	0.3	6713.333333	3
4	2014	ZH	0.5	4028.000000	4
DataFrame as specialized dictionary
Similarly, we can also think of a DataFrame as a specialization of dictionary. Where a dictionary maps a key to a value, a DataFrame maps a column name to a Series of column data. For example, asking for the 'area' attribute returns the Series object containing the areas we saw earlier:

From a list of dicts
Any list of dictionaries can be made into a DataFrame. We'll use a simple list comprehension to create some data:

In [ ]:
data = [{'a': i, 'b':10* i}for i in range(6)]
print(data)
pd.DataFrame(data)
Even if some keys in the dictionary are missing, Pandas will fill them in with NaN (i.e., "not a number") values:

In [ ]:
pd.DataFrame([{'aa': 1, 'bb': 2}, {'bb': 3, 'cc': 6}])
From a two-dimensional NumPy array
Given a two-dimensional array of data, we can create a DataFrame with any specified column and index names. If omitted, an integer index will be used for each:

In [ ]:
pd.DataFrame(np.random.randint(2, 12),
             columns=['foo', 'bar'],
             index=['a', 'b', 'c'])
The Pandas Index Object
We have seen here that both the Series and DataFrame objects contain an explicit index that lets you take reference and modify data. This Index object is an interesting structure in itself, and it can be thought of either as an immutable array or as an ordered set (technically a multi-set, as Index objects may contain repeated values). Those views have some interesting consequences in the operations available on Index objects. As a simple example, let's construct an Index from a list of integers:

In [ ]:
ind = pd.Index([20, 34, 57, 7, 1, 8])
ind
Index as immutable array
The Index in many ways operates like an array. For example, we can use standard Python indexing notation to retrieve values or slices:

In [ ]:
ind[1]
In [ ]:
ind[::]
Index objects also have many of the attributes familiar from NumPy arrays:

In [ ]:
print(ind.size, ind.shape, ind.ndim, ind.dtype)
One difference between Index objects and NumPy arrays is that indices are immutable–that is, they cannot be modified via normal means:

In [ ]:
ind[1] = 0
This immutability makes it safer to share indices between multiple DataFrames and arrays, without the potential for side effects from inadvertent index modification.

Operating on Data in Pandas
One of the essential pieces of NumPy is the ability to perform quick element-wise operations, both with basic arithmetic (addition, subtraction, multiplication, etc.) and with more sophisticated operations (trigonometric functions, exponential and logarithmic functions, etc.). Pandas inherits much of this functionality from NumPy, and the ufuncs are key to this.

Pandas includes a couple useful twists, however: for unary operations like negation and trigonometric functions, these ufuncs will preserve index and column labels in the output, and for binary operations such as addition and multiplication, Pandas will automatically align indices when passing the objects to the ufunc. This means that keeping the context of data and combining data from different sources–both potentially error-prone tasks with raw NumPy arrays–become essentially foolproof with Pandas. We will additionally see the well-defined operations between one-dimensional Series structures and two-dimensional DataFrame structures.

Ufuncs: Index Preservation
Because Pandas is designed to work with NumPy, any NumPy ufunc will work on Pandas Series and DataFrame objects. Let's start by defining a simple Series and DataFrame on which to demonstrate this:

In [ ]:
rng = np.random.RandomState(15)
ser = pd.Series(rng.randint(0, 10, 4))
ser
Out[ ]:
0    8
1    5
2    5
3    7
dtype: int64
In [ ]:
dfr = pd.DataFrame(rng.randint(0, 10, (5, 4)),
                  columns=['A', 'B', 'C', 'D'])
dfr
Out[ ]:
A	B	C	D
0	0	7	5	6
1	1	7	0	4
2	9	7	5	3
3	6	8	2	1
4	1	0	5	2
If we apply a NumPy ufunc on either of these objects, the result will be another Pandas object with the indices preserved:

In [ ]:
np.exp(ser)
Out[ ]:
0    2980.957987
1     148.413159
2     148.413159
3    1096.633158
dtype: float64
Or, for a slightly more complex calculation:

In [ ]:
np.sin(dfr * np.pi / 4)
Out[ ]:
A	B	C	D
0	0.000000	-7.071068e-01	-0.707107	-1.000000e+00
1	0.707107	-7.071068e-01	0.000000	1.224647e-16
2	0.707107	-7.071068e-01	-0.707107	7.071068e-01
3	-1.000000	-2.449294e-16	1.000000	7.071068e-01
4	0.707107	0.000000e+00	-0.707107	1.000000e+00
Universal Functions: Index Alignment
For binary operations on two Series or DataFrame objects, Pandas will align indices in the process of performing the operation. This is very convenient when working with incomplete data, as we'll see in some of the examples that follow.

Index alignment in Series
As an example, suppose we are combining two different data sources, and find only the top three US states by area and the top three US states by population:

In [ ]:
area = pd.Series({'Alaska': 1723337, 'Texas': 695662,
                  'California': 423967}, name='area')
population = pd.Series({'California': 38332521, 'Texas': 26448193,
                        'New York': 19651127}, name='population')
print(area)
population
Alaska        1723337
Texas          695662
California     423967
Name: area, dtype: int64
Out[ ]:
California    38332521
Texas         26448193
New York      19651127
Name: population, dtype: int64
Let's see what happens when we divide these to compute the population density:

In [ ]:
population / area
Out[ ]:
Alaska              NaN
California    90.413926
New York            NaN
Texas         38.018740
dtype: float64
The resulting array contains the union of indices of the two input arrays, which could be determined using standard Python set arithmetic on these indices:

In [ ]:
area.index | population.index
Out[ ]:
Index(['Alaska', 'California', 'New York', 'Texas'], dtype='object')
In [ ]:
A = pd.Series([2, 4, 6], index=[0, 1, 2])
B = pd.Series([1, 3, 5], index=[1, 2, 3])
print(A)
print(B)
B
A + B
0    2
1    4
2    6
dtype: int64
1    1
2    3
3    5
dtype: int64
Out[ ]:
0    NaN
1    5.0
2    9.0
3    NaN
dtype: float64
If using NaN values is not the desired behavior, the fill value can be modified using appropriate object methods in place of the operators. For example, calling A.add(B) is equivalent to calling A + B, but allows optional explicit specification of the fill value for any elements in A or B that might be missing:

In [ ]:
A.add(B, fill_value=0)
Out[ ]:
0    2.0
1    5.0
2    9.0
3    5.0
dtype: float64
The following table lists Python operators and their equivalent Pandas object methods:

Python Operator	Pandas Method(s)
+	add()
-	sub(), subtract()
*	mul(), multiply()
/	truediv(), div(), divide()
//	floordiv()
%	mod()
**	pow()
Ufuncs: Operations Between DataFrame and Series
When performing operations between a DataFrame and a Series, the index and column alignment is similarly maintained. Operations between a DataFrame and a Series are similar to operations between two-dimensional and one-dimensional NumPy array. Consider one common operation, where we find the difference of a two-dimensional array and one of its rows:

Data wrangling
Getting the data in the shape that we want is the single most time consuming task in the life of the Data Scientist. Sometimes it can be the most frustrating.

Merge operations
By merging we mean combining different data sets by linking rows with one or more keys. The basic syntax is very simple.

In [ ]:
df
Out[ ]:
Year	Province	Literacy	nonsense	Serie_aligned
0	2013	FL	0.2	10065.000000	0
1	2014	FL	0.1	20140.000000	1
2	2013	NH	0.5	4026.000000	2
3	2014	NH	0.3	6713.333333	3
4	2014	ZH	0.5	4028.000000	4
In [ ]:
df2 = pd.DataFrame({"Province": ["FL", "NH", "ZH"], "Population": ["100000", "200000", "300000"]})
df2
Out[ ]:
Province	Population
0	FL	100000
1	NH	200000
2	ZH	300000
Let's say we want a dataset with year, literacy, province and population. We can create it from df and df2.

In [ ]:
df.merge(df2)  # merge is smart! If there are overlapping names, it uses those for the merge
Out[ ]:
Year	Province	Literacy	nonsense	Serie_aligned	Population
0	2013	FL	0.2	10065.000000	0	100000
1	2014	FL	0.1	20140.000000	1	100000
2	2013	NH	0.5	4026.000000	2	200000
3	2014	NH	0.3	6713.333333	3	200000
4	2014	ZH	0.5	4028.000000	4	300000
If the column names are different, you need to specify them explicitely

In [ ]:
df3 = pd.DataFrame({"province": ["FL", "NH"], "Population": ["100000", "200000"]})
df3
df.merge(df3, right_on='province', left_on='Province')
Out[ ]:
Year	Province	Literacy	nonsense	Serie_aligned	province	Population
0	2013	FL	0.2	10065.000000	0	FL	100000
1	2014	FL	0.1	20140.000000	1	FL	100000
2	2013	NH	0.5	4026.000000	2	NH	200000
3	2014	NH	0.3	6713.333333	3	NH	200000
What happened? Zuid Holland is weg!

By default merge does inner joins. If you want a different type of join, you can specify it.

In [ ]:
df4 = pd.DataFrame({"Province": ["FL", "NH", "UT"], "Population": ["100000", "200000", "50000"]})
df.merge(df4, how='outer')
Check this out:

In [ ]:
df5 = pd.DataFrame({"Province": ["FL", "NH", "FL"], "Population": ["100000", "200000", "50000"]})
print(df)
df.merge(df5, how='outer')
   Year Province  Literacy      nonsense  Serie_aligned
0  2013       FL       0.2  10065.000000              0
1  2014       FL       0.1  20140.000000              1
2  2013       NH       0.5   4026.000000              2
3  2014       NH       0.3   6713.333333              3
4  2014       ZH       0.5   4028.000000              4
Out[ ]:
Year	Province	Literacy	nonsense	Serie_aligned	Population
0	2013	FL	0.2	10065.000000	0	100000
1	2013	FL	0.2	10065.000000	0	50000
2	2014	FL	0.1	20140.000000	1	100000
3	2014	FL	0.1	20140.000000	1	50000
4	2013	NH	0.5	4026.000000	2	200000
5	2014	NH	0.3	6713.333333	3	200000
6	2014	ZH	0.5	4028.000000	4	NaN
This was a many-to-many merge. Even though if you think about it, the behavior is what you expect, you might still not think about it and be surprised!

Combining data with overlap
Sometimes some data is missing, and it can be "patched" with another dataset. Let's take a look.

In [ ]:
serie_a = pd.Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan],
                     index=['f', 'e', 'd', 'c', 'b', 'a'])
serie_b = pd.Series(np.arange(len(serie_a), dtype=np.float64),
                 index=['f', 'e', 'd', 'c', 'b', 'a'])
In [ ]:
serie_a
Out[ ]:
f    NaN
e    2.5
d    NaN
c    3.5
b    4.5
a    NaN
dtype: float64
In [ ]:
serie_b
Out[ ]:
f    0.0
e    1.0
d    2.0
c    3.0
b    4.0
a    5.0
dtype: float64
Let's say we want to update a with the values from b. The num-pythonic way to do that is

In [ ]:
pd.Series(np.where(pd.isnull(serie_a), serie_b, serie_a), index=serie_a.index)
Out[ ]:
f    0.0
e    2.5
d    2.0
c    3.5
b    4.5
a    5.0
dtype: float64
That's a bit verbose for something so simple. What about this:

In [ ]:
serie_a.combine_first(serie_b)
Out[ ]:
f    0.0
e    2.5
d    2.0
c    3.5
b    4.5
a    5.0
dtype: float64
In [ ]:

In [ ]:

In [ ]:
